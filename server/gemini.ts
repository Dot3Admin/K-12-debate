import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import type { AgentHumor } from "@shared/schema";
import { buildHumorTonePrompt, type ContextType } from "./utils/HumorToneController.js";

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

export interface GeminiChatMessage {
  role: "user" | "model";
  parts: string;
}

export interface GeminiChatOptions {
  model?: string;
  temperature?: number;
  maxOutputTokens?: number;
  topP?: number;
  topK?: number;
}

export interface GeminiChatResponse {
  text: string;
  sources?: {
    chunks: Array<{ title: string; url: string }>;
    supports: Array<{
      startIndex: number;
      endIndex: number;
      text: string;
      chunkIndices: number[];
    }>;
  };
}

// ì•ˆì „ ì„¤ì • (ê¸°ë³¸ê°’)
const safetySettings = [
  {
    category: HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
];

/**
 * 503 ê³¼ë¶€í•˜ ì—ëŸ¬ ì²´í¬
 */
function isOverloadError(error: any): boolean {
  const errorMsg = error.message?.toLowerCase() || '';
  const errorStatus = error.status;
  return (
    errorStatus === 503 || 
    errorMsg.includes('503') || 
    errorMsg.includes('overload') || 
    errorMsg.includes('unavailable')
  );
}

/**
 * Exponential backoffë¥¼ ì‚¬ìš©í•œ sleep í•¨ìˆ˜
 */
async function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Gemini API ì—ëŸ¬ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ë¡œ ë³€í™˜
 */
function normalizeGeminiError(error: any): Error {
  if (error.message?.includes("quota")) {
    return new Error("Gemini API quota exceeded. Please check your usage limits.");
  } else if (error.message?.includes("safety")) {
    return new Error("Content was blocked by Gemini safety filters.");
  } else if (error.message?.includes("API key")) {
    return new Error("Invalid Gemini API key. Please check your GEMINI_API_KEY environment variable.");
  } else {
    return new Error(`Gemini API error: ${error.message || "Unknown error"}`);
  }
}

/**
 * ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ í•¨ìˆ˜ ì‹¤í–‰ wrapper
 */
async function executeWithRetries<T>(
  fn: () => Promise<T>,
  maxRetries: number = 5
): Promise<T> {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error: any) {
      const isLastAttempt = attempt === maxRetries - 1;
      const isRetryable = isOverloadError(error);
      
      if (isRetryable && !isLastAttempt) {
        const waitTime = (2 ** attempt) * 1000; // 1s, 2s, 4s, 8s, 16s
        console.log(`[ğŸ”„ RETRY] Gemini overload error (attempt ${attempt + 1}/${maxRetries}). Waiting ${waitTime}ms...`);
        await sleep(waitTime);
        continue;
      }
      
      // ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ê±°ë‚˜ ë§ˆì§€ë§‰ ì‹œë„ ì‹¤íŒ¨
      console.error("[Gemini API Error]", error);
      throw normalizeGeminiError(error);
    }
  }
  
  throw new Error("Max retries exceeded");
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì‘ë‹µ ìƒì„± (ì¬ì‹œë„ ë¡œì§ ì—†ìŒ - ë‚´ë¶€ í•¨ìˆ˜)
 */
async function _generateGeminiChatResponseInternal(
  systemPrompt: string,
  messages: GeminiChatMessage[],
  options: GeminiChatOptions = {}
): Promise<GeminiChatResponse> {
  const {
    model = "gemini-2.0-flash-lite",
    // ğŸŒ¡ï¸ ì‚¬ì‹¤ ê¸°ë°˜ ì‘ë‹µì„ ìœ„í•œ ë‚®ì€ temperature ì„¤ì •
    // í•™ìŠµëœ êµ¬ì²´ì  ì •ë³´ ì¸ìš©ì„ ìš°ì„ ì‹œ (ì°½ì˜ì  ì¬êµ¬ì„± ì–µì œ)
    temperature = 0.35,  // ì‚¬ì‹¤ íšŒìƒ ìµœì í™” (0.3~0.4 ë²”ìœ„)
    maxOutputTokens = 4096,
    topP = 0.6,          // ê²°ì •ë¡ ì  ì¶œë ¥ í¸í–¥ (ì¸ìš©ë¬¸ ìš°ì„ )
    topK = 40,
  } = options;

  const geminiModel = genAI.getGenerativeModel({
    model,
    systemInstruction: systemPrompt,
    generationConfig: {
      temperature,
      maxOutputTokens,
      topP,
      topK,
    },
    safetySettings,
  });

  // ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³€í™˜
  let history = messages.slice(0, -1).map(msg => ({
    role: msg.role,
    parts: [{ text: msg.parts }],
  }));

  // Gemini API ìš”êµ¬ì‚¬í•­: íˆìŠ¤í† ë¦¬ëŠ” "user"ë¡œ ì‹œì‘í•´ì•¼ í•¨
  // "model"ë¡œ ì‹œì‘í•˜ëŠ” ë©”ì‹œì§€ ì œê±°
  while (history.length > 0 && history[0].role === "model") {
    history = history.slice(1);
  }

  const lastMessage = messages[messages.length - 1];

  // ì±„íŒ… ì„¸ì…˜ ì‹œì‘
  const chat = geminiModel.startChat({
    history,
  });

  // ë©”ì‹œì§€ ì „ì†¡ ë° ì‘ë‹µ ë°›ê¸°
  const result = await chat.sendMessage(lastMessage.parts);
  const response = result.response;
  
  // ì‘ë‹µ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
  const responseText = response.text();
  console.log(`[ğŸ¤– GEMINI RESPONSE] Length: ${responseText.length} chars`);
  
  if (responseText.length === 0) {
    console.error(`[âŒ EMPTY RESPONSE] Gemini returned empty text!`);
    console.error(`[âŒ RESPONSE DEBUG]`, JSON.stringify({
      candidates: (response as any).candidates,
      promptFeedback: (response as any).promptFeedback
    }, null, 2));
  }
  
  return {
    text: responseText,
    sources: undefined  // Google Search ë¹„í™œì„±í™”ë¡œ í•­ìƒ undefined
  };
}

/**
 * í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
 * í•œê¸€ ëª…ì‚¬ íŒ¨í„´, ìˆ«ì, ì˜ë¬¸ ê³ ìœ ëª…ì‚¬ ì¶”ì¶œ
 */
function extractKeywords(text: string, maxKeywords: number = 5): string[] {
  if (!text) return [];
  
  // ë¶ˆìš©ì–´ (stopwords)
  const stopwords = new Set(['ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ë˜', 'ì„', 'ë¥¼', 'ì´ë¥¼', 'ê·¸ë¥¼', 'ì €ë¥¼', 
    'ì˜', 'ê°€', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ë¿', 'ê¹Œì§€', 'ë¶€í„°', 'ì—ê²Œ', 'í•œí…Œ']);
  
  // 1. í•œê¸€ 2ê¸€ì ì´ìƒ (ëª…ì‚¬ íŒ¨í„´)
  const koreanWords = text.match(/[ê°€-í£]{2,}/g) || [];
  
  // 2. ì˜ë¬¸ ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë‹¨ì–´ (ê³ ìœ ëª…ì‚¬)
  const properNouns = text.match(/[A-Z][a-z]+/g) || [];
  
  // 3. ìˆ«ì í¬í•¨ íŒ¨í„´ (ì—°ë„, ë‚ ì§œ ë“±)
  const numbers = text.match(/\d{4}ë…„?|\d{1,2}ì›”|\d{1,2}ì¼/g) || [];
  
  // ëª¨ë“  í‚¤ì›Œë“œ í•©ì¹˜ê¸°
  const allKeywords = [...koreanWords, ...properNouns, ...numbers]
    .filter(word => !stopwords.has(word) && word.length >= 2)
    .slice(0, maxKeywords);
  
  return allKeywords;
}

/**
 * í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ë¹Œë”
 * Primary: agentName + userMessage + ë‹µë³€ í•µì‹¬ í‚¤ì›Œë“œ
 * Fallback: answerContent ì¼ë¶€
 */
function buildHybridQuery(params: {
  agentName: string;
  userMessage: string;
  answerContent: string;
}): { primary: string; fallback: string } {
  const { agentName, userMessage, answerContent } = params;
  
  // ë‹µë³€ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
  const keywords = extractKeywords(answerContent, 3);
  
  // Primary Query: ì—ì´ì „íŠ¸ëª… + ì§ˆë¬¸ + í•µì‹¬ í‚¤ì›Œë“œ
  const primaryParts = [
    agentName,
    userMessage.slice(0, 100),
    ...keywords
  ].filter(Boolean);
  
  const primary = primaryParts.join(' ').slice(0, 200);
  
  // Fallback Query: ë‹µë³€ í…ìŠ¤íŠ¸ ì¼ë¶€
  const fallback = `"${answerContent.slice(0, 150)}" ê´€ë ¨ ì¶œì²˜`;
  
  console.log(`[ğŸ”¨ QUERY BUILDER] Primary: "${primary.slice(0, 80)}..."`);
  console.log(`[ğŸ”¨ QUERY BUILDER] Fallback: "${fallback.slice(0, 80)}..."`);
  
  return { primary, fallback };
}

/**
 * íƒ€ì„ì•„ì›ƒ í—¬í¼ í•¨ìˆ˜
 */
function withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error(`Timeout after ${timeoutMs}ms`)), timeoutMs)
    )
  ]);
}

/**
 * ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ Google Search ìˆ˜í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ì „ëµ)
 * â±ï¸ 7ì´ˆ íƒ€ì„ì•„ì›ƒ ê°•ì œ ì ìš©
 */
export async function searchMessageSources(params: {
  agentName: string;
  userMessage: string;
  answerContent: string;
}): Promise<{
  success: boolean;
  sources: Array<{ title: string; url: string; snippet?: string }>;
  error?: string;
}> {
  const SEARCH_TIMEOUT = 7000; // 7ì´ˆ íƒ€ì„ì•„ì›ƒ
  
  try {
    const geminiModel = genAI.getGenerativeModel({
      model: "gemini-2.0-flash-lite",
      tools: [{
        google_search: {}
      }] as any,
    });

    // í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ìƒì„±
    const queries = buildHybridQuery(params);
    
    // Primary Query ì‹œë„ (7ì´ˆ íƒ€ì„ì•„ì›ƒ)
    console.log(`[ğŸ” PRIMARY SEARCH] Agent: ${params.agentName}, Query: "${queries.primary.slice(0, 50)}..."`);
    const startTime = Date.now();
    
    let result;
    try {
      result = await withTimeout(
        geminiModel.generateContent({
          contents: [{
            role: "user",
            parts: [{ text: queries.primary }]
          }]
        }),
        SEARCH_TIMEOUT
      );
    } catch (timeoutError) {
      console.log(`[â±ï¸ SEARCH TIMEOUT] Primary query timed out after ${SEARCH_TIMEOUT}ms - returning empty sources`);
      return { success: true, sources: [] };
    }

    let response = result.response;
    let groundingMetadata = (response as any).candidates?.[0]?.groundingMetadata;

    // Primary Queryì—ì„œ ì¶œì²˜ë¥¼ ëª» ì°¾ìœ¼ë©´ Fallback ì‹œë„ (ë‚¨ì€ ì‹œê°„ë§Œí¼ë§Œ ì‹œë„)
    if (!groundingMetadata || !groundingMetadata.groundingChunks || groundingMetadata.groundingChunks.length === 0) {
      const elapsed = Date.now() - startTime;
      const remainingTime = Math.max(1000, SEARCH_TIMEOUT - elapsed); // ìµœì†Œ 1ì´ˆ ë³´ì¥
      
      console.log(`[âš ï¸ PRIMARY FAILED] No sources found, trying fallback query (timeout: ${remainingTime}ms)...`);
      
      try {
        result = await withTimeout(
          geminiModel.generateContent({
            contents: [{
              role: "user",
              parts: [{ text: queries.fallback }]
            }]
          }),
          remainingTime
        );
      } catch (timeoutError) {
        console.log(`[â±ï¸ SEARCH TIMEOUT] Fallback query timed out - returning empty sources`);
        return { success: true, sources: [] };
      }

      response = result.response;
      groundingMetadata = (response as any).candidates?.[0]?.groundingMetadata;
    }

    const totalTime = Date.now() - startTime;
    console.log(`[â±ï¸ SEARCH TIME] ${totalTime}ms`);

    if (!groundingMetadata || !groundingMetadata.groundingChunks) {
      console.log(`[ğŸ” SEARCH] Both queries failed â†’ 0ê°œ ì¶œì²˜ ë°œê²¬`);
      return { success: true, sources: [] };
    }

    const sources = groundingMetadata.groundingChunks.map((chunk: any) => ({
      title: chunk.web?.title || "ì¶œì²˜",
      url: chunk.web?.uri || "",
      snippet: chunk.web?.snippet || ""
    })).filter((s: any) => s.url);

    console.log(`[âœ… SEARCH] Found ${sources.length}ê°œ ì¶œì²˜ in ${totalTime}ms`);
    
    return { success: true, sources };
  } catch (error: any) {
    console.error("[âŒ SEARCH ERROR]", error);
    return { 
      success: false, 
      sources: [], 
      error: error?.message || "Search failed" 
    };
  }
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì‘ë‹µ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
 */
export async function generateGeminiChatResponse(
  systemPrompt: string,
  messages: GeminiChatMessage[],
  options: GeminiChatOptions = {}
): Promise<GeminiChatResponse> {
  return executeWithRetries(() => 
    _generateGeminiChatResponseInternal(systemPrompt, messages, options)
  );
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„± (OpenAI generateChatResponseì™€ ìœ ì‚¬í•œ ì¸í„°í˜ì´ìŠ¤)
 */
export async function generateGeminiResponse(
  userMessage: string,
  agentName: string,
  agentDescription: string,
  conversationHistory: Array<{ role: "user" | "assistant"; content: string }>,
  speechStyle: string,
  personality: string,
  additionalPrompt: string,
  model: string = "gemini-2.0-flash",
  maxTokens: number = 4096
): Promise<{ message: string; usedDocuments?: any[]; sources?: { chunks: Array<{ title: string; url: string }>; supports: Array<{ startIndex: number; endIndex: number; text: string; chunkIndices: number[] }> } }> {
  // ğŸ¯ additionalPromptê°€ ë¹„ì–´ìˆìœ¼ë©´ ê°„ë‹¨í•œ í…œí”Œë¦¿ ì‚¬ìš©
  // ì•„ë‹ˆë©´ additionalPromptë¥¼ ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš© (Non-Negotiable Tone Rules í¬í•¨)
  let systemPrompt: string;
  
  if (additionalPrompt && additionalPrompt.trim().length > 0) {
    // âœ… enhancedProfessionalPromptê°€ ì „ë‹¬ëœ ê²½ìš° - ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    // (Non-Negotiable Tone Rules, Canon, Style, Relation ëª¨ë‘ í¬í•¨)
    systemPrompt = additionalPrompt;
    console.log(`[ğŸ¯ Gemini Prompt] ${agentName}: ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (${additionalPrompt.length}ì)`);
    console.log(`[ğŸ¯ Gemini Prompt Preview] ${systemPrompt.slice(0, 500)}...`);
  } else {
    // âŒ í´ë°±: ê°„ë‹¨í•œ í…œí”Œë¦¿ ì‚¬ìš© (ë ˆê±°ì‹œ)
    systemPrompt = `You are ${agentName}. ${agentDescription}

Speech Style: ${speechStyle}
Personality: ${personality}`;
    console.log(`[âš ï¸ Gemini Prompt] ${agentName}: í´ë°± í…œí”Œë¦¿ ì‚¬ìš© (additionalPrompt ì—†ìŒ)`);
  }

  // ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  const geminiMessages: GeminiChatMessage[] = conversationHistory.map(msg => ({
    role: msg.role === "user" ? "user" : "model",
    parts: msg.content
  }));

  // í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
  geminiMessages.push({
    role: "user",
    parts: userMessage
  });

  // Gemini API í˜¸ì¶œ
  // ğŸ¯ temperature/topP/topKëŠ” ê¸°ë³¸ê°’(0.5/0.75/20) ì‚¬ìš© - compliance-driven personaìš©
  const response = await generateGeminiChatResponse(
    systemPrompt,
    geminiMessages,
    {
      model,
      maxOutputTokens: maxTokens,
      // temperature 1.0 ì œê±° - ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©
    }
  );

  // ğŸ§¹ ë¦¬ë“¬íƒœê·¸ ì œê±° (ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•Šë„ë¡) - OpenAIì™€ ë™ì¼
  const { removeRhythmTags } = await import('./openai');
  const cleanedMessage = removeRhythmTags(response.text);

  return {
    message: cleanedMessage,
    usedDocuments: [],
    sources: response.sources
  };
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
 */
export async function* generateGeminiChatResponseStream(
  systemPrompt: string,
  messages: GeminiChatMessage[],
  options: GeminiChatOptions = {}
): AsyncGenerator<string, void, unknown> {
  const {
    model = "gemini-2.0-flash-lite",
    // ğŸŒ¡ï¸ ì‚¬ì‹¤ ê¸°ë°˜ ì‘ë‹µì„ ìœ„í•œ ë‚®ì€ temperature ì„¤ì •
    // í•™ìŠµëœ êµ¬ì²´ì  ì •ë³´ ì¸ìš©ì„ ìš°ì„ ì‹œ (ì°½ì˜ì  ì¬êµ¬ì„± ì–µì œ)
    temperature = 0.35,  // ì‚¬ì‹¤ íšŒìƒ ìµœì í™” (0.3~0.4 ë²”ìœ„)
    maxOutputTokens = 4096,
    topP = 0.6,          // ê²°ì •ë¡ ì  ì¶œë ¥ í¸í–¥ (ì¸ìš©ë¬¸ ìš°ì„ )
    topK = 40,
  } = options;

  // ìŠ¤íŠ¸ë¦¼ ìƒì„± ë¶€ë¶„ì—ë§Œ ì¬ì‹œë„ ë¡œì§ ì ìš© (chunk yield ì „)
  const streamResult = await executeWithRetries(async () => {
    const geminiModel = genAI.getGenerativeModel({
      model,
      systemInstruction: systemPrompt,
      generationConfig: {
        temperature,
        maxOutputTokens,
        topP,
        topK,
      },
      safetySettings,
    });

    // ğŸ”„ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ contents ë°°ì—´ë¡œ ë³€í™˜ (generateContentStream í˜•ì‹)
    const contents: any[] = [];
    
    // íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ ì¶”ê°€
    for (const msg of messages.slice(0, -1)) {
      contents.push({
        role: msg.role,
        parts: [{ text: msg.parts }]
      });
    }
    
    // ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ê°€
    const lastMessage = messages[messages.length - 1];
    contents.push({
      role: lastMessage.role,
      parts: [{ text: lastMessage.parts }]
    });

    // Gemini API ìš”êµ¬ì‚¬í•­: contentsëŠ” "user"ë¡œ ì‹œì‘í•´ì•¼ í•¨
    while (contents.length > 0 && contents[0].role === "model") {
      contents.shift();
    }

    // âœ… generateContentStream ì‚¬ìš© (chat.sendMessageStream ëŒ€ì‹ )
    return await geminiModel.generateContentStream({ contents });
  });
  
  // ìŠ¤íŠ¸ë¦¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ë©´ chunkë“¤ì„ yield (ì¬ì‹œë„ ì—†ìŒ)
  for await (const chunk of streamResult.stream) {
    const text = chunk.text();
    if (text) {
      yield text;
    }
  }
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„±
 */
export async function generateGeminiEmbedding(text: string): Promise<number[]> {
  try {
    const model = genAI.getGenerativeModel({ model: "text-embedding-004" });
    
    const result = await model.embedContent(text);
    const embedding = result.embedding;
    
    return embedding.values;
  } catch (error: any) {
    console.error("[Gemini Embedding Error]", error);
    throw new Error(`Gemini embedding error: ${error.message || "Unknown error"}`);
  }
}

/**
 * Gemini í´ë¼ì´ì–¸íŠ¸ í™•ì¸ (API í‚¤ ìœ íš¨ì„± ê²€ì¦)
 */
export async function validateGeminiApiKey(): Promise<boolean> {
  try {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      console.error("[Gemini] API key not found in environment variables");
      return false;
    }

    // ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­ìœ¼ë¡œ API í‚¤ ìœ íš¨ì„± í™•ì¸
    const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-lite" });
    const result = await model.generateContent("Hello");
    const response = result.response;
    
    return !!response.text();
  } catch (error: any) {
    console.error("[Gemini] API key validation failed:", error.message);
    return false;
  }
}

/**
 * Geminië¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± (JSON ì¶œë ¥)
 */
export async function generateGeminiStructuredResponse<T>(
  systemPrompt: string,
  userPrompt: string,
  options: GeminiChatOptions = {}
): Promise<T> {
  const {
    model = "gemini-2.0-flash-lite",
    temperature = 0.1,
    maxOutputTokens = 2048,
  } = options;

  try {
    const geminiModel = genAI.getGenerativeModel({
      model,
      systemInstruction: systemPrompt + "\n\nYou must respond with valid JSON only. Do not include any other text.",
      generationConfig: {
        temperature,
        maxOutputTokens,
        responseMimeType: "application/json",
      },
      safetySettings,
    });

    const result = await geminiModel.generateContent(userPrompt);
    const response = result.response;
    const text = response.text();

    // JSON íŒŒì‹±
    const parsedData = JSON.parse(text);
    return parsedData as T;
  } catch (error: any) {
    console.error("[Gemini Structured Response Error]", error);
    throw new Error(`Gemini structured response error: ${error.message || "Unknown error"}`);
  }
}

/**
 * ğŸ¯ Knowledge Router - ê²€ìƒ‰ ì „ëµ íŒë‹¨
 * 3ë‹¨ í­í¬ìˆ˜(Waterfall) ì‹œìŠ¤í…œì˜ ì²« ë‹¨ê³„: ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì „ëµ ê²°ì •
 * @returns "internal" | "rag" | "web"
 */
export async function determineSearchStrategy(
  userQuery: string,
  agentName: string,
  agentDescription: string
): Promise<"internal" | "rag" | "web"> {
  const systemPrompt = `You are a search strategy analyzer. Your job is to determine the best information retrieval strategy for answering user questions.`;

  const userPrompt = `Analyze this query and determine the best strategy:

**User Query:** "${userQuery}"

**Agent Context:** 
- Name: ${agentName}
- Description: ${agentDescription}

**Strategy Options:**
1. "internal": LLMì˜ ê¸°ë³¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ê²½ìš° (ê²€ìƒ‰ ë¶ˆí•„ìš”)
   - ì¼ë°˜ì ì¸ ì¸ì‚¬, ì² í•™ì  ì§ˆë¬¸, ìƒì‹ì  ì§ˆë¬¸
   - í•´ë‹¹ ì¸ë¬¼ì— ëŒ€í•œ ë„ë¦¬ ì•Œë ¤ì§„ ê¸°ë³¸ ì •ë³´
   Examples: "ì•ˆë…•í•˜ì„¸ìš”", "ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”?", "ë‹¹ì‹ ì˜ ì§ì—…ì€?"

2. "rag": íŠ¹ì • ê³¼ê±° ì‚¬ê±´, ë°œì–¸, ë¬¸ì„œí™”ëœ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°
   - ê³¼ê±° ë…¼ë€, ìŠ¤ìº”ë“¤, ì‚¬ê±´ì— ëŒ€í•œ ì§ˆë¬¸ (ì´ë¯¸ ë³´ë„ëœ ê²ƒ)
   - êµ¬ì²´ì ì¸ ë°œì–¸, ê²½ë ¥, ì´ë ¥
   Examples: "ëª…í’ˆë°± ìˆ˜ìˆ˜ ì‚¬ê±´ì€?", "ê³¼ê±° ë°œì–¸ì— ëŒ€í•´", "ê²½ë ¥ ì´ë ¥"

3. "web": **ì˜¤ì§ ì‹¤ì‹œê°„/ìµœì‹  ì •ë³´**ê°€ í•„ìš”í•œ ê²½ìš°ë§Œ
   - ì§€ë‚œ 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤
   - "ì˜¤ëŠ˜", "ë°©ê¸ˆ", "ìµœì‹ " ê°™ì€ ì‹¤ì‹œê°„ í‘œí˜„
   Examples: "ì˜¤ëŠ˜ ë¬´ìŠ¨ ì¼ì´?", "ë°©ê¸ˆ ë‚˜ì˜¨ ë‰´ìŠ¤ëŠ”?", "í˜„ì¬ ìƒí™©ì€?"

**ìš°ì„ ìˆœìœ„ (ì¤‘ìš”!):**
1. ëŒ€ë¶€ë¶„ì˜ ì§ˆë¬¸ â†’ "internal" (LLMì´ ì´ë¯¸ ì•Œê³  ìˆìŒ)
2. íŠ¹ì • ì‚¬ê±´/ë¬¸ì„œ í•„ìš” â†’ "rag" (DB ê²€ìƒ‰)
3. ì‹¤ì‹œê°„ ì •ë³´ë§Œ â†’ "web" (ìµœí›„ì˜ ìˆ˜ë‹¨, ë¹„ìš© ë†’ìŒ)

**í•µì‹¬ ê·œì¹™:**
- ë…¼ë€, ìŠ¤ìº”ë“¤, ê³¼ê±° ì‚¬ê±´ â†’ "rag" (ì´ë¯¸ ë³´ë„ë˜ì–´ DBì— ìˆì„ ê°€ëŠ¥ì„± ë†’ìŒ)
- "ì˜¤ëŠ˜", "ë°©ê¸ˆ", "ìµœì‹ ", "í˜„ì¬" ê°™ì€ ì‹¤ì‹œê°„ í‚¤ì›Œë“œ â†’ "web"
- í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ â†’ "internal" ìš°ì„  (LLMì´ ì‹¤íŒ¨í•˜ë©´ ìë™ìœ¼ë¡œ ragë¡œ fallback)

Output JSON format:
{
  "strategy": "internal" | "rag" | "web",
  "reason": "brief explanation in Korean"
}`;

  try {
    const result = await generateGeminiStructuredResponse<{
      strategy: "internal" | "rag" | "web";
      reason: string;
    }>(systemPrompt, userPrompt, {
      model: "gemini-2.0-flash-lite",
      temperature: 0.1,
    });

    console.log(`[ğŸ¯ Knowledge Router] ${agentName}: ${userQuery.slice(0, 50)}... â†’ Strategy: ${result.strategy} (${result.reason})`);
    
    return result.strategy;
  } catch (error: any) {
    console.error("[Knowledge Router Error]", error);
    // Fallback: ì—ëŸ¬ ì‹œ RAG ì „ëµ ì‚¬ìš© (ì•ˆì „í•œ ê¸°ë³¸ê°’)
    console.log(`[ğŸ¯ Knowledge Router] Error occurred, defaulting to "rag" strategy`);
    return "rag";
  }
}

/**
 * ğŸš« ìì—°ìŠ¤ëŸ¬ìš´ ê±°ì ˆ ë©”ì‹œì§€ ìƒì„±
 * ìºë¦­í„°ì˜ ë§íˆ¬ì™€ í˜ë¥´ì†Œë‚˜ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì „ë¬¸ ì˜ì—­ ì™¸ ì§ˆë¬¸ì„ ê±°ì ˆ
 */
export async function generateNaturalRefusal(
  agentName: string,
  agentDescription: string,
  agentKnowledgeDomain: string,
  userQuestion: string,
  userLanguage: string = 'ko'
): Promise<string> {
  const systemPrompt = `ë‹¹ì‹ ì€ ìºë¦­í„° "${agentName}"ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê±°ì ˆ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

ìºë¦­í„° ì •ë³´:
- ì´ë¦„: ${agentName}
- ì„¤ëª…: ${agentDescription}
- ì „ë¬¸ ì˜ì—­: ${agentKnowledgeDomain}

ì‚¬ìš©ì ì§ˆë¬¸: "${userQuestion}"

**ì‘ì—…:** ì´ ì§ˆë¬¸ì€ ìºë¦­í„°ì˜ ì „ë¬¸ ì˜ì—­("${agentKnowledgeDomain}") ë°–ì…ë‹ˆë‹¤. ìºë¦­í„°ì˜ ë§íˆ¬ì™€ ì„±ê²©ì„ ìœ ì§€í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê±°ì ˆí•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ê±°ì ˆ ë©”ì‹œì§€ ê°€ì´ë“œë¼ì¸:**
1. ìºë¦­í„°ì˜ ë§íˆ¬, ì„±ê²©, ì–´ì¡°ë¥¼ ìœ ì§€
2. ì „ë¬¸ ì˜ì—­ì´ ì•„ë‹ˆë¼ëŠ” ì ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬
3. ë„ˆë¬´ í˜•ì‹ì ì´ì§€ ì•Šê³ , ìºë¦­í„°ë‹µê²Œ í‘œí˜„
4. 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
5. ì–¸ì–´: ${userLanguage === 'ko' ? 'í•œêµ­ì–´' : 'English'}

**ì¢‹ì€ ì˜ˆì‹œ:**
- "ê·¸ ë¶€ë¶„ì€ ì œê°€ ì˜ ëª¨ë¥´ëŠ” ì˜ì—­ì´ë¼ì„œìš”. ì €ëŠ” ${agentKnowledgeDomain}ì— ëŒ€í•´ì„œë§Œ ì œëŒ€ë¡œ ì´ì•¼ê¸°í•  ìˆ˜ ìˆì–´ìš”."
- "ì£„ì†¡í•˜ì§€ë§Œ ê·¸ê±´ ì œ ì „ë¬¸ ë¶„ì•¼ê°€ ì•„ë‹ˆë„¤ìš”. ì €ëŠ” ${agentKnowledgeDomain} ìª½ìœ¼ë¡œ ë” ì˜ ë‹µë³€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

**ë‚˜ìœ ì˜ˆì‹œ:**
- "I cannot answer that question." (ë„ˆë¬´ formal)
- "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." (ìºë¦­í„° ë§íˆ¬ ì—†ìŒ)

ê±°ì ˆ ë©”ì‹œì§€ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):`;

  try {
    const result = await model.generateContent(systemPrompt);
    const refusalMessage = result.response?.text()?.trim() || '';
    
    console.log(`[ğŸš« ìì—°ìŠ¤ëŸ¬ìš´ ê±°ì ˆ] ${agentName}: "${refusalMessage}"`);
    return refusalMessage;
  } catch (error) {
    console.error(`[âŒ Refusal Generation Error]`, error);
    // Fallback: ê¸°ë³¸ ê±°ì ˆ ë©”ì‹œì§€
    return userLanguage === 'ko'
      ? `ì£„ì†¡í•˜ì§€ë§Œ ê·¸ ë¶€ë¶„ì€ ì œ ì „ë¬¸ ë¶„ì•¼ê°€ ì•„ë‹ˆë¼ì„œ ì •í™•íˆ ë§ì”€ë“œë¦¬ê¸° ì–´ë µë„¤ìš”. ì €ëŠ” ${agentKnowledgeDomain}ì— ëŒ€í•´ì„œë§Œ ì´ì•¼ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.`
      : `I'm sorry, but that's not my area of expertise. I can only discuss ${agentKnowledgeDomain}.`;
  }
}
