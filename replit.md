# LoBo - University AI Chatbot System

## Overview
LoBo is a full-stack TypeScript AI chatbot system designed for Korean universities, offering intelligent assistance to students and faculty. Its primary purpose is to provide a seamless, multilingual, and personalized AI experience through a modern, mobile-first React frontend. Key capabilities include real-time chat, advanced document analysis, comprehensive agent management, dynamic multi-agent debates with character orchestration, and a "Canon Lock" mode for stringent theological responses. LoBo aims to enhance the educational experience through advanced AI interactions and robust content handling.

## User Preferences
Preferred communication style: Simple, everyday language.
Performance optimization priority: Fast startup and responsive UI.

## System Architecture
### UI/UX Decisions
The frontend, built with React 18, TypeScript, and Vite, uses Radix UI and Tailwind CSS for a responsive, mobile-first design. The chat UI is inspired by Apple Messages, with clean flat designs for login and admin interfaces. It features an adaptive color scheme, standardized modals, and consistent button styling. The home layout is card-based, reminiscent of Windows Phone Live Tiles, incorporating 3D flip animations, real-time message previews, customizable grid layouts, folder organization, shortcut cards, and drag-and-drop editing with icon and color customization.

### Technical Implementations
The backend uses Node.js with Express.js (TypeScript, ES modules) and Replit Auth for session-based authentication. Core features include:
-   **Agent System**: Category-based, multilingual agents with custom icons/colors, expertise-based @mention routing, advanced character orchestration for multi-agent debates, and a "Canon Lock" mode. A persona system enforces knowledge domains and maintains speech styles.
-   **Chat Interface**: Real-time messaging, document integration, message reactions, notifications, streaming responses, and dual LLM provider support (OpenAI/Gemini).
-   **Document Processing**: AI summarization, key point extraction, full-text indexing, and agent-linked contextual responses, with OCR support for scanned documents.
-   **Master Admin System**: A dashboard for system monitoring, user/agent/document/organization management, QA logs, and bulk operations.
-   **Internationalization**: Full multilingual support for UI and AI responses with intelligent language detection.
-   **AI Response Enhancement**: Advanced conversational diversity, context-aware personalization, and robust handling of incomplete responses, including multi-turn conversation systems with duplicate response prevention and caching.
-   **RAG System with Semantic Search**: Utilizes embedding-based vector search (OpenAI `text-embedding-3-large` with PostgreSQL `pgvector`), hybrid search (keyword + semantic similarity), multilingual query support, and token optimization. It incorporates a **Smart TTL (Living Knowledge Base)** for automatic freshness management of Google Search results, using Gemini 2.5 Flash for content classification and intelligent expiration dates. A **One-Shot Adaptive RAG** architecture significantly reduces costs through a single-LLM-call workflow, incorporating an Entity Profile database, adaptive TTL, a unified `generateUltimateResponse()` function for all outputs, code-level date filtering, and citation preservation.
-   **Token Optimization Engine**: Intelligent conversation history compression, dynamic context adjustment, and optimized system prompts.
-   **Hybrid Search and Dialog State Management**: Two-tier query strategy for accurate source retrieval and centralized dialog state management.
-   **CallNAsk System**: Anonymous guest access for public agent chats with Gemini-powered character auto-generation, disambiguation, and duplicate prevention. Features a 3-stage fallback system for answer retrieval (LLM knowledge, DB cache, Google Search) and comprehensive guest tracking and analytics. An **Agentic RAG Architecture** (Reasoning ‚Üí Search ‚Üí Filter) uses a Chain-of-Thought pattern for query generation. A **Parallel Execution Pipeline** reduces latency for answer generation and perspective extraction. A **Debate-Style Chat Interface** enables interactive perspective-based debates.
-   **AI Character Recommendation**: Multi-language recommendations based on Era/Reality √ó Perspective/Stance √ó Role/Position, including "Ordinary Person Characters" across a 4-level maturity system.
-   **Descriptive Persona Architecture**: Preserves character authenticity using priority hierarchies, prohibited phrases, and tone audit logging.
-   **Dynamic Dialogue Template v3**: Advanced conversational rhythm and emotional connectivity for multi-character debates.
-   **Scenario-Based Turn Management**: Combines static relationship matrices with dynamic scenario summaries to enhance multi-agent conversations.
-   **Multi-modal Expressive Avatar System v2**: Dynamic character emotion avatars displayed alongside chat messages, supporting 16 distinct emotions. Uses **Google Cloud Vertex AI Imagen 3** (`imagen-3.0-generate-001`) as the primary image generation model with DALL-E 3 fallback. Generates 4x4 grids of emotion avatars per character for cost optimization in a satirical caricature style.
-   **Instant Insight Architecture v2.0 "Step 21"**: Universal Domain-Agnostic Dynamic Extraction system for key metrics and architects from search results, using frequency-based prioritization and dynamic injection into answers.
-   **VERDICT v6.0 "Podcast Edition"**: Upgraded framing for multi-agent debates simulating a podcast studio with first-person "I" perspective. Enforces "Facts are Sacred, Style is Free" and "Podcast-Style Interaction" rules, with dynamic date injection, evidence-based character casting, and a "Key Metric ‚Üí Architect ‚Üí Conflict" chain of thought. Minimum 8 turns enforced with structured flow.
-   **Dynamic Anchor Teaser (Step 35)**: Two-phase response architecture for sub-8-second initial response. Phase 1 uses Gemini 2.0-flash-lite to generate a 3-bullet fact summary + context-aware closing teaser (e.g., "ÎØºÌù¨ÏßÑ ÎåÄÌëúÏôÄ ÌïòÏù¥Î∏å Í≤ΩÏòÅÏßÑÏùò Í∞ÄÍ∞ê ÏóÜÎäî ÏÑ§Ï†Ñ, Î∞îÎ°ú ÏãúÏûëÌï©ÎãàÎã§"). Phase 2 runs full VERDICT debate generation in background. Phase 2 casting is independent of Phase 1's detected figures for better accuracy.
-   **Persona Localization (Step 36)**: Korean figures must use Korean catchphrases only (e.g., "Fake News!" ‚Üí "Í∞ÄÏßú Îâ¥Ïä§ÏûÖÎãàÎã§!", "Wait!" ‚Üí "Ïû†ÍπêÎßåÏöî!"). English flavor text allowed only for foreign figures (Trump, Musk). Phase 1 anchor enforces 5W1H event reporting (Who, What, When, Where, Why) instead of dictionary definitions.
-   **Phase 1 Fast Response Fix (Step 38)**: Critical fix for Phase 1 anchor teaser - removed Google Search Grounding which caused 50-second delays and topic drift (returning trending news instead of question-relevant content). Now uses question-based analysis only with 8-second timeout, figure validation to prevent detecting wrong characters, and fallback extraction using regex patterns.
-   **UI/UX Polish: Charismatic Host (Step 39)**: Refactored Phase 1 prompt to remove robotic "meta-labels" (### Breaking News, Subject:, etc). Uses "Bridge Technique" to frame conflicts instead of summarizing facts. Varies opening phrases to prevent repetition. The anchor is now a charismatic debate host, not a news anchor. Example: "5Ï°∞? ÎàÑÍµ∞ ÏÑ†Í≤¨ÏßÄÎ™ÖÏù¥Îùº ÌïòÍ≥†, ÎàÑÍµ∞ ÎèÑÎ∞ïÏù¥Îùº ÌïòÏ£†. Í≥ºÏó∞ ÎàÑÍ∞Ä ÎßûÏùÑÍπåÏöî?"
-   **Loading State and Timeout Management**: Frontend waiting timeout extended to 180 seconds with improved loading UX. Refactored loading state management for asynchronous operations, using server-side ID-based comparison for reliable termination of loading spinners even with multiple concurrent mutations.
-   **Real-Time Token Streaming (Step 43)**: SSE-based streaming architecture for live broadcast experience. Uses cumulative text approach (each chunk contains full text from start) with monotonic update guards to prevent flickering. Unique negative IDs per debate turn (-1 for anchor, -2/-3/... for turns) ensure independent streaming. Backend controls typing speed via `delayMs` parameter. Explicit `agent_streaming_complete` events signal cleanup for accurate typing indicators.
-   **Embedded Suggestion Chips (Step 46)**: Context-preserving speaker recommendations generated directly within the VERDICT debate response. Eliminates separate API calls by embedding `suggestion_chips` in the LLM's JSON output. Chips include `action` types: `more_info` (existing speakers for deeper insights) and `new_entry` (new relevant figures). Server-side validation filters irrelevant global celebrities (Elon Musk, Yuval Harari, etc.) and ensures `more_info` speakers appear in the dialogue. Frontend reads chips from message metadata with API fallback for backwards compatibility. **Step 46 Fix**: Changed useEffect logic to check `speakerChips.length > 0` instead of `speakersLoadedRef.current` to prevent false-positive early termination when API fallback sets the ref before embedded chips arrive.
-   **Google News Integration (Step 47)**: Real-time news discovery for VERDICT debates with 9 category tabs (Home, Recommended, Korea, World, Business, Technology, Entertainment, Sports, Health). Fetches from Google News RSS feeds with caching and scheduled updates at 9 AM and 7 PM KST. Uses **Fast Mode** for initial cache (13-second initialization, no LLM calls) with `waitForCacheReady()` for cold start handling. Optionally uses Gemini 2.0-flash-lite to transform news headlines into VERDICT-style questions. Features scrollable section tabs with icons, news cards with source badges, and click-to-debate functionality. API endpoints: `/api/news`, `/api/news/:section`, `/api/news-status`.
-   **Perplexity-Style Inline Citations**: Simplified citation display below message content. Features a `CitationContent` component that renders message content with ReactMarkdown, then displays numbered `CitationBadge` components (no header text). Each badge shows a popover on click with source title, domain (extracted from URL), and snippet, linking to the original URL. Sources stored as array `[{url, title, snippet}]` in the message's `sources` field. Step 44 sequential display queue fixed to preserve sources: on initial load, all messages are displayed immediately with `displayedMessages = messages`; new messages during session use sequential display. **Step 48**: All debate turns now receive sources (distributed from `debateScenario.searchResults`), and anchor teaser styled as chatbot message with üéôÔ∏è ÏßÑÌñâÏûê avatar. Database schema updated to persist `agentName` and `senderName` columns for reliable anchor detection. Hybrid anchor detection uses metadata-first approach (`agentName === 'üéôÔ∏è ÏßÑÌñâÏûê'`) with legacy content-heuristic fallback. **Step 49 Per-Turn Source Filtering**: Each debate turn now displays only the sources it actually referenced, not all sources from the entire debate. Uses Gemini API's `groundingSupports` metadata with `startIndex/endIndex` offsets and `chunkIndices` to map citations to individual turns. Handles JSON escape characters via `JSON.stringify().slice(1,-1)` for accurate text matching. Safe fallback returns `null` (no sources) when matching fails.

### System Design Choices
The database uses PostgreSQL (Neon serverless) with Drizzle ORM. The schema supports users, agents, conversations, messages, documents, card folders, card layouts, guest sessions, and guest analytics, including document embeddings. Structured Timeline Data is stored in a `timeline_data` (JSONB) field for deterministic historical query disambiguation.

## External Dependencies
-   **OpenAI API**: GPT-4o, Vision API, `text-embedding-3-large`, DALL-E 3 (avatar fallback).
-   **Google Gemini API**: Gemini 2.5-pro, 2.5-flash, 2.0-flash, 2.0-flash-lite.
-   **Google Cloud Vertex AI**: Imagen 3 (`imagen-3.0-generate-001`) for avatar generation.
-   **Neon Database**: Serverless PostgreSQL hosting.
-   **Replit Auth**: Authentication service.
-   **TypeScript**: Primary development language.
-   **Drizzle ORM / Drizzle Kit**: Database interaction.
-   **Tailwind CSS**: Utility-first CSS framework.
-   **Radix UI**: Accessible UI component library.
-   **Lucide React**: Icon library.
-   **Tesseract OCR**: Scanned document text extraction.
-   **Poppler**: PDF to image conversion.
-   **Sharp**: Image processing library.
-   **ua-parser-js**: User-Agent parsing for guest session tracking.